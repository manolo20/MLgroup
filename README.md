# MLgroup

Mathematics / Machine Learning group
---

The objective of this repository is to have a place where we can keep track of all our presentations.

During our weekly sessions, we will be covering the following topics:

---
1. Generative Models

    Generative Adversarial Networks ([GAN](https://arxiv.org/abs/1406.2661)).
    Variational Autoencoders ([VAE](https://arxiv.org/abs/1312.6114))
    Stochastic Backpropagation and Approximate Inference in Deep Generative Models ([paper](https://arxiv.org/abs/1401.4082))
    Flow based methods (normalized flows)
    * [AVB](AVB): Adversarial Variational Bayes: Unifying Variational Autoencoders and Generative Adversarial Networks ([paper](https://arxiv.org/abs/1701.04722))
    * [Gumbel-SoftmaxVAE](Gumbel-SoftmaxVAE): Categorical Reparameterization with Gumbel-Softmax ([paper](https://arxiv.org/abs/1611.01144))
    The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables ([paper](https://arxiv.org/abs/1611.00712))
    * VQVAE: Neural Discrete Representation Learning ([paper](https://arxiv.org/abs/1711.00937))
    * TripleGAN: Triple Generative Adversarial Nets ([paper](https://arxiv.org/abs/1703.02291))
    * ConditionalVAE: Semi-Supervised Learning with Deep Generative Models ([paper](https://arxiv.org/abs/1406.5298))
    * [AAE](AAE): Adversarial Autoencoders ([paper](https://arxiv.org/abs/1511.05644))
    * f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization ([paper](https://arxiv.org/abs/1606.00709))
    * ImprovedGAN: Improved Techniques for Training GANs ([paper](https://arxiv.org/abs/1606.03498))
    * [DCGAN](DCGAN): Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks ([paper](https://arxiv.org/abs/1511.06434))
    * WGAN: Wasserstein Generative Adversarial Networks ([paper](http://proceedings.mlr.press/v70/arjovsky17a.html))


**Tutorials**
* NIPS 2016 Tutorial: Generative Adversarial Networks ([paper](https://arxiv.org/abs/1701.00160) [slides](https://media.nips.cc/Conferences/2016/Slides/6202-Slides.pdf) [video](https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Generative-Adversarial-Networks))
* CVPR 2017 Tutorial: Theory and Application of Generative Adversarial Networks ([slides](https://raw.githubusercontent.com/mingyuliutw/cvpr2017_gan_tutorial/master/gan_tutorial.pdf) [video](https://www.youtube.com/watch?v=KudkR-fFu_8))
* Tutorial on Variational Autoencoders ([paper](https://arxiv.org/abs/1606.05908))
* Bayesian Deep Learning and Generic Bayesian Inference ([slides](https://www.dropbox.com/s/xcawad601yplnm5/blei.pdf?dl=0))

1.1. Differncial Privacy:  
Area of research which seeks to provide rigorous, statistical guarantees against what an adversary can infer from learning the results of some randomized algorithm ([Amazon Research](https://borjaballe.github.io/slides/dp-tutorial-long.pdf))

---
2. Information Theory, Information Geometry and Natural Gradients

    Basic tools (definitions, etc)
    Go through a textbook or some basic review papers.
---
3. Reinforcement Learning

    Bandits
    Theory/background of Markov Decision Process (MDP)
    Optimality
    Value iteration, policy iteration
    Value based methods
    Policy search (policy gradient) methods
---
 4. Statistical Learning Theory

    Framework; Rademacher Complexity; VC dimension; basic bounds
    SVMs
---
 5. Semi Supervised Learning (SSL)

    Overall assumptions; positive and negative theoretical results
    Graph based methods (Laplacian framework)
    Label propagation methods
    Modern Neural Network methods
---
 6. Active Learning

    Learning theory
    Fisher information methods
    ensemble methods
---
 7. Metric Learning

    Formal theory (Mahalanobis methods)
    Triplet loss function
    Siamese networks and other modern approaches (embeddings, etc)
---
 8. Neural Networks

    Basics (activation functions, computation graphs, backpropagation, loss functions and objective functions)
    Basics II (standard practices in training/testing; detecting overfitting/underfitting; regularization methods)
    Convolutional Neural Networks 
    Recurrent Neural Networks/Long Short Term Memory
    Attention
    Auxiliary tasks (e.g. multi-headed NN's)
---
 9. Kernel Methods

    Reproducing kernel Hilbert spaces
    Kernel density estimation
    approximating kernel methods
---
- Manifold Learning
- Bayesian methods; Gaussian processes; Markov Chain Monte Carlo(MCMC)
- Natural Language Processing (NLP) 
- Image Processing/Computer Vision
- Adversarial methods
- Transfer learning (zero shot, few shot, one shot learning)
- Optimization methods
